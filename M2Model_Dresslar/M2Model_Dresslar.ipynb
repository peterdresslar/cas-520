{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Started\n",
    "!uv pip install pynetlogo matplotlib seaborn pandas\n",
    "\n",
    "# Set the path to your NetLogo installation\n",
    "# Note! This is OS and machine dependent.\n",
    "# Perhaps someone has an NL docker image out there?\n",
    "# See https://pynetlogo.readthedocs.io/en/latest/_docs/pynetlogo.html#pynetlogo.core.NetLogoLink\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Assignment: Schelling Segregation Model\n",
    "\n",
    "*CAS 520, Peter Dresslar*\n",
    "\n",
    "For this assignment we will use [pynetlogo](https://pynetlogo.readthedocs.io/) to capture and report simulation outputs. An excellent and relevant example appears [here](https://pynetlogo.readthedocs.io/en/latest/_docs/introduction.html)\n",
    "\n",
    "**Important** pynetlogo will apparently only work reliably with NetLogo 6.3.0. While that presents challenges of its own, it is also important to note the the model we are using, `segregation`, *must* have a version number that matches that version of NetLogo. So, grabbing the latest version of the model may not work without tweaking the file. The model with adjusted version number is in this repository.\n",
    "\n",
    "`pynetlogo` requires a Java install, for which I used `brew install cask temurin` (on Apple silicon). While the jvm path can be overridden, it appears that pynetlogoʻs implementation of JPype works to automatially find the installed JVM from that cask. Note that I wound up having to point to the `app` directory within the Netlogo base installation.\n",
    "\n",
    "## Cluster Analysis\n",
    "\n",
    "I just read (this paper)[https://doi.org/10.1063/5.0115101] and itʻs pretty interesting. Our breakpoint is pretty close to their reported 67 percent.\n",
    "\n",
    "## Step 1: First Analysis\n",
    "\n",
    "### Experiment 1: Set density to 80% and similarity wanted to 30% and run the simulation several times.\n",
    "\n",
    "### Experiment 2: Keeping density at 80%, change the similarity threshold to 90%.\n",
    "\n",
    "### Experiment 3: While the model is still running from step 2, slowly move the similarity slider to the left and note when the model behaviour changes and segregation emerges.\n",
    "\n",
    "### Experiment 4: Rerun the simulation a few times with 80% density and similarity threshold at the tipping point you discovered.\n",
    "\n",
    "\n",
    "We will begin Step 1 by building our experiment harness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python architecture: arm64\n",
      "Using JVM at: /Library/Java/JavaVirtualMachines/temurin-24.jdk/Contents/Home/lib/server/libjvm.dylib\n",
      "Using NetLogo at: /Users/peterdresslar/Workspace/NetLogo-6.3.0/app\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pynetlogo\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "base_model = \"./Segregation.nlogo\" # (copied into this directory!)\n",
    "\n",
    "def initialize_netlogo():\n",
    "\n",
    "    ### Some unplesantness for pynetlogo setup:\n",
    "    # Get Java home (should return ARM Java if that's what's installed)\n",
    "    java_home = subprocess.check_output(['/usr/libexec/java_home']).decode().strip()\n",
    "    jvm_path = os.path.join(java_home, 'lib', 'server', 'libjvm.dylib')\n",
    "    netlogo_path = '/Users/peterdresslar/Workspace/NetLogo-6.3.0/app'\n",
    "\n",
    "    # Print for verification\n",
    "    print(f\"Python architecture: {platform.machine()}\")\n",
    "    print(f\"Using JVM at: {jvm_path}\")\n",
    "    print(f\"Using NetLogo at: {netlogo_path}\")\n",
    "\n",
    "    # Get a netlogo instance\n",
    "    netlogo = pynetlogo.NetLogoLink(\n",
    "        gui=False,  # cannot set to true for macs\n",
    "        netlogo_home=netlogo_path,\n",
    "        # jvm_path=jvm_path\n",
    "    )\n",
    "\n",
    "    return netlogo\n",
    "\n",
    "def find_breakpoint(netlogo, model, density, precision):\n",
    "    \"\"\"\n",
    "    This is tricky! We start with the given density and similarity wanted.\n",
    "    We know from manual testing that there is a breakpoint at which point the model \n",
    "    will reduce to 0% unhappy. We also can observe that this \"collapse\" occurs within\n",
    "    1000 ticks, and that the go procedure will halt the model at that point.\n",
    "    \n",
    "    We can run a simple binary \"search\" to find this point,\n",
    "    by running the model with similarity-wanted values between 1.0 and 90.0.\n",
    "\n",
    "    If the model stops within 1000 ticks, we know that the breakpoint is higher than the \n",
    "    searched similarity-wanted value. If the model runs the full 1000 steps, we know that\n",
    "    the breakpoint is lower than the searched similarity-wanted value.\n",
    "\n",
    "    Since we are setting values programatically, we have the luxury of looking beyond the integer values of similarity-wanted.\n",
    "\n",
    "    args:\n",
    "        netlogo: the netlogo instance\n",
    "        model: the model to run\n",
    "\n",
    "    returns:\n",
    "        breakpoint: the similarity-wanted value at which the model breaks down\n",
    "\n",
    "    \"\"\"\n",
    "    upper_bound = 100.0  # this is for values of similarity wanted\n",
    "    lower_bound = 1.0 # not sure how the model would deal with zeroes!\n",
    "    breakpoint = None\n",
    "\n",
    "    precision_step = 10 ** (-precision)  # 10e-precision, in other words.\n",
    "    \n",
    "    iteration = 0\n",
    "    while breakpoint is None:\n",
    "        iteration += 1\n",
    "        midpoint = round((upper_bound + lower_bound) / 2, precision) # round to 4 decimal places\n",
    "        print(f\"Iteration {iteration} at {midpoint}\")\n",
    "        netlogo.load_model(model)\n",
    "        netlogo.command(f\"set density {density}\")\n",
    "        netlogo.command(f\"set %-similar-wanted {midpoint}\")\n",
    "        netlogo.command(\"setup\")\n",
    "        \n",
    "        netlogo.command(\"repeat 1000 [go]\")\n",
    "        # we should be able to see if the model halted early by checking the step number \n",
    "\n",
    "        ticks = netlogo.report(\"ticks\")\n",
    "        print(f\"Ticks: {ticks}\")\n",
    "\n",
    "        if ticks < 1000:\n",
    "            lower_bound = midpoint + precision_step\n",
    "        else:\n",
    "            upper_bound = midpoint - precision_step\n",
    "\n",
    "        if upper_bound - lower_bound < precision_step:\n",
    "            breakpoint = midpoint\n",
    "    \n",
    "    return breakpoint\n",
    "        \n",
    "    \n",
    "def cluster_analysis(turtle_data):\n",
    "    \"\"\"\n",
    "    Analyze clustering patterns in turtle data from NetLogo.\n",
    "    \n",
    "    Parameters:\n",
    "    turtle_data - List containing [x_array, y_array, color_array]\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary of cluster metrics\n",
    "    \"\"\"\n",
    "    results = 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_experiment(netlogo, model, experiment_name, number_of_runs, density, percent_similar_wanted, max_ticks):\n",
    "    \"\"\"\n",
    "    Run the model with the given parameters and return the results.\n",
    "\n",
    "    args:\n",
    "        netlogo: the netlogo instance\n",
    "        model: the model to run\n",
    "        experiment_name: the name of the experiment\n",
    "        number_of_runs: the number of times to run the model\n",
    "        density: the density of the model\n",
    "        similarity_wanted: the similarity wanted of the model\n",
    "        max_ticks: the maximum number of ticks to run the model\n",
    "\n",
    "    returns:\n",
    "        data: a dictionary containing experiment results\n",
    "        includes:\n",
    "            - number of runs\n",
    "            - density\n",
    "            - similarity wanted\n",
    "            - average average similarity values\n",
    "            - average time to happiness, in ticks (or N/A if model never halts)\n",
    "            - cluster analysis results\n",
    "\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"number_of_runs\": number_of_runs,\n",
    "        \"density\": density,\n",
    "        \"percent_similar_wanted\": percent_similar_wanted,\n",
    "        \"average_similarity_values\": [],\n",
    "        \"time_to_happiness_values\": [],\n",
    "        \"cluster_analysis_values\": [],\n",
    "        \"average_average_similarity_values\": [],\n",
    "        \"average_time_to_happiness\": [],\n",
    "        \"average_cluster_analysis_values\": []\n",
    "    }\n",
    "\n",
    "    # collectors\n",
    "    time_to_happiness_values = []\n",
    "    average_similarity_values = []\n",
    "    cluster_analysis_values = []\n",
    "\n",
    "    for run, _ in enumerate(range(number_of_runs), 1):   # is there an easier way to do this? yes! I :heart enumerate.\n",
    "        print(f\"Experiment name {experiment_name}, Run {run} of {number_of_runs}\")\n",
    "\n",
    "        netlogo.load_model(model)\n",
    "        \n",
    "        netlogo.command(f\"set density {density}\")\n",
    "        netlogo.command(f\"set %-similar-wanted {percent_similar_wanted}\")\n",
    "        netlogo.command(\"setup\")\n",
    "        \n",
    "        # run the model. it will halt from inside netlogo if it meets the stopping condition (no unhappy turtles)\n",
    "        netlogo.command(f\"repeat {max_ticks} [go]\")\n",
    "\n",
    "        ticks = netlogo.report(\"ticks\")\n",
    "        if ticks < max_ticks:   # we will assume that the model did not achieve happiness on the very last tick!\n",
    "            run_time_to_happiness = ticks\n",
    "        else:\n",
    "            run_time_to_happiness = None\n",
    "\n",
    "        run_average_similarity = netlogo.report(\"percent-similar\") \n",
    "        \n",
    "        # grab the turtle data for cluster analysis\n",
    "        # this is almost word for word from the pynetlogo introduction, cell 6\n",
    "        x = netlogo.report(\"map [t -> [xcor] of t] sort turtles\")\n",
    "        y = netlogo.report(\"map [t -> [ycor] of t] sort turtles\")\n",
    "        turtle_color = netlogo.report(\"map [t -> [color] of t] sort turtles\")\n",
    "        turtle_happiness = netlogo.report(\"map [t -> [happy?] of t] sort turtles\")\n",
    "        turtle_data = [x, y, turtle_color, turtle_happiness]\n",
    "\n",
    "        print(turtle_data)\n",
    "        run_cluster_analysis = cluster_analysis(turtle_data)  # need to write function\n",
    "\n",
    "        ticks_print = ticks if ticks else \"N/A\"   # donʻt break the print statement\n",
    "        print(f\" Run {run} complete, ticks: {ticks_print}, average similarity: {run_average_similarity}, cluster analysis: {run_cluster_analysis}\")\n",
    "\n",
    "        # store to collectors\n",
    "        time_to_happiness_values.append(run_time_to_happiness)\n",
    "        average_similarity_values.append(run_average_similarity)\n",
    "        cluster_analysis_values.append(run_cluster_analysis)\n",
    "\n",
    "    # move collectors to data\n",
    "    data[\"time_to_happiness_values\"] = time_to_happiness_values\n",
    "    data[\"average_similarity_values\"] = average_similarity_values\n",
    "    data[\"cluster_analysis_values\"] = cluster_analysis_values\n",
    "\n",
    "    # letʻs do some post-processing\n",
    "    data[\"average_time_to_happiness\"] = sum(time_to_happiness_values) / len(time_to_happiness_values)\n",
    "    data[\"average_average_similarity_values\"] = sum(average_similarity_values) / len(average_similarity_values)\n",
    "    #data[\"average_cluster_analysis_values\"] = sum(cluster_analysis_values) / len(cluster_analysis_values) if cluster_analysis_values else 0\n",
    "\n",
    "    print(f\"Experiment {experiment_name} complete, average time to happiness: {data['average_time_to_happiness']}, average average similarity: {data['average_average_similarity_values']}, average cluster analysis: {data['average_cluster_analysis_values']}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Since we are initializing netlogo here, you must run this cell before running the experiments.\n",
    "\n",
    "netlogo = initialize_netlogo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready to run our experiments, but before we do that, we have a great opportunity to scan for phase transition points, not just at density 80, but at all densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding breakpoint for density 50.0\n",
      "Iteration 1 at 50.5\n",
      "Ticks: 20.0\n",
      "Iteration 2 at 75.25\n",
      "Ticks: 396.0\n",
      "Iteration 3 at 87.63\n",
      "Ticks: 1000.0\n",
      "Iteration 4 at 81.44\n",
      "Ticks: 1000.0\n",
      "Iteration 5 at 78.34\n",
      "Ticks: 333.0\n",
      "Iteration 6 at 79.89\n",
      "Ticks: 752.0\n",
      "Iteration 7 at 80.66\n",
      "Ticks: 1000.0\n",
      "Iteration 8 at 80.28\n",
      "Ticks: 1000.0\n",
      "Iteration 9 at 80.09\n",
      "Ticks: 1000.0\n",
      "Iteration 10 at 79.99\n",
      "Ticks: 737.0\n",
      "Iteration 11 at 80.04\n",
      "Ticks: 1000.0\n",
      "Iteration 12 at 80.02\n",
      "Ticks: 1000.0\n",
      "Finding breakpoint for density 50.1\n",
      "Iteration 1 at 50.5\n",
      "Ticks: 23.0\n",
      "Iteration 2 at 75.25\n",
      "Ticks: 621.0\n",
      "Iteration 3 at 87.63\n",
      "Ticks: 1000.0\n",
      "Iteration 4 at 81.44\n",
      "Ticks: 1000.0\n",
      "Iteration 5 at 78.34\n",
      "Ticks: 559.0\n",
      "Iteration 6 at 79.89\n",
      "Ticks: 440.0\n",
      "Iteration 7 at 80.66\n",
      "Ticks: 1000.0\n",
      "Iteration 8 at 80.28\n"
     ]
    }
   ],
   "source": [
    "def plot_density_breakpoint_relationship(breakpoints_df):\n",
    "    \"\"\"\n",
    "    Create a detailed plot showing the relationship between density and \n",
    "    similarity breakpoint in the Schelling model.\n",
    "    \n",
    "    Parameters:\n",
    "    breakpoints_df - DataFrame with 'density' and 'breakpoint' columns\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Set up the plot style\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Create the main plot\n",
    "    ax = sns.lineplot(\n",
    "        data=breakpoints_df, \n",
    "        x=\"density\", \n",
    "        y=\"breakpoint\",\n",
    "        marker='o',\n",
    "        linewidth=2,\n",
    "        markersize=8\n",
    "    )\n",
    "    \n",
    "    # Add a horizontal line at y=75 (the theoretical threshold)\n",
    "    plt.axhline(y=75, color='r', linestyle='--', alpha=0.5, label='75% Threshold')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"Critical Similarity Threshold by Population Density\", fontsize=16)\n",
    "    plt.xlabel(\"Population Density (%)\", fontsize=14)\n",
    "    plt.ylabel(\"Critical Similarity Threshold (%)\", fontsize=14)\n",
    "    \n",
    "    # Add a text annotation explaining the plot\n",
    "    plt.figtext(0.5, 0.01, \n",
    "                \"The critical similarity threshold is the minimum percentage of similar neighbors\\n\"\n",
    "                \"required for happiness that results in complete segregation.\",\n",
    "                ha=\"center\", fontsize=12)\n",
    "    \n",
    "    # Ensure y-axis starts at 0 or appropriate minimum\n",
    "    y_min = max(0, breakpoints_df['breakpoint'].min() - 5)\n",
    "    y_max = min(100, breakpoints_df['breakpoint'].max() + 5)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    # Add grid for easier reading\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.legend()\n",
    "    \n",
    "    return plt.gcf()  # Return the figure for further customization if needed\n",
    "\n",
    "min_density = 50\n",
    "max_density = 70\n",
    "step_size = 0.1\n",
    "precision = 2\n",
    "\n",
    "# with those sweep parameters, we can search breakpoints for all densities\n",
    "# place them into a dataframe\n",
    "# and plot the results\n",
    "\n",
    "breakpoints = []\n",
    "\n",
    "for density in np.arange(min_density, max_density, step_size):   # np.arange takes a float for step_size\n",
    "    print(f\"Finding breakpoint for density {density}\")\n",
    "    breakpoint = find_breakpoint(netlogo, base_model, density=density, precision=precision)\n",
    "    breakpoints.append(breakpoint)\n",
    "\n",
    "breakpoints_df = pd.DataFrame({\"density\": range(min_density, max_density, step_size), \"breakpoint\": breakpoints})\n",
    "\n",
    "plot_density_breakpoint_relationship(breakpoints_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1 = run_experiment(netlogo, base_model, experiment_name=\"Experiment 1\", number_of_runs=2, density=80, percent_similar_wanted=30, max_ticks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
